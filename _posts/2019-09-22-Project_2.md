---
layout: post
title: Second Project - Predicting Riyadh House Prices Using Linear Regression
---
## Project Goal:

<p align="justify">My goal in this project was to use linear regression in order to estimate the sale price of a house in Riyadh, Saudi Arabia by 
using eSimsar website database.</p>


### Look at the **eSimsar website**
Click the Link: [**eSimsar**](https://www.esimsar.com/)


## Project Overview:
<p align="justify">In this project, I am going to develop and evaluate the performance and the predictive power of a model trained and tested on data collected from<a href= "https://www.esimsar.com/"> eSimsar </a>. Once I get an excellent model fit, I am going to use this model to predict the monetary value of a house located in Riyadh's area.</p>


## Project Approach:

These are the steps that I followed to achieve my project goal:-

### Web Scraping:

<p align="justify">In this first step, I used <b>BeautifulSoup</b> to extract the page data from <a href= "https://www.esimsar.com/"> eSimsar </a>website. I extracted 2662 rows and this is the code used for web scraping the eSimsar pages.</p> 
```
list_url=[]
for x in range (1,266):
    url = 'https://www.esimsar.com/ar/search?c=1&ob=mr&page='+str(x)+'&q=%D8%A7%D9%84%D8%B1%D9%8A%D8%A7%D8%B6&t=35'
    response = requests.get(url)
    list_url.append(response.text)
    
size = []
bathroom = []
bed = []
price = []
neighborhood = []
region = []

for i in list_url:
    page = i
    soup = BeautifulSoup(page, "lxml")
    soup.prettify()
    for j in range(0,25):
        size.append(soup.find_all(class_='card__content')[j].find_all('p',attrs={'class':"card__property-amenity     card__property-amenity--area"})[0].text.strip())
        try:
            bathroom.append(soup.find_all(class_='card__content')[j].find_all('p',attrs={'class':"card__property-amenity card__property-amenity--bathrooms"})[0].text.strip())
        except:
            bathroom.append(int(0))
        try:
            bed.append(soup.find_all(class_='card__content')[j].find_all('p',attrs={'class':"card__property-amenity card__property-amenity--bedrooms"})[0].text.strip())
        except:
            bed.append(int(0))
        price.append(soup.find_all(class_='card__content')[j].find_all(class_='card__price-value')[0].text.strip())
        neighborhood.append(soup.find_all(class_='card__content')[j].find_all(class_='card__header')[0].find_all(class_='card__location')[0].text.split(',')[0].strip())
        region.append(soup.find_all(class_='card__content')[j].find_all(class_='card__header')[0].find_all(class_='card__location')[0].text.split(',')[1].strip())

```

<p align="justify">After I extracted the data, I saved it in csv file. The below figure shows the information that I extracted from the pages.</p>

![Image test]({{ site.url }}/images/house1.png)



### Cleaning Data & Exploratory Data Analysis:

<p align="justify">In the second step, I started to cleaning the data. I did some cleaning and filtering on the columns. I made the size column of the houses on the range between 200 and 1300, and the price column to be in range between 200,000 and 20,000,000. Also, since my data are not that big I deleted the neighborhood column and I added a new column called Region_Eng which is same as Region but translated to English. After the data cleaning, The below figure shows the remaining data.</p>

![Image test]({{ site.url }}/images/house2.png)



### Developing Models:

<p align="justify">In this step, I started to develop multiple model and chose the best one to test my test-data on it. in the below models, I will show the OLS model, Residual and QQ plot, and cross validation R-squared. These are the code of OLS model and QQ plot.</p>

```
def Model_OLS(x,y):
    x = sm.add_constant(x)
    model = sm.OLS(y,x)
    fit = model.fit()
    return fit.summary()
```
```
def QQ_plot(x,y):
    plt.figure(figsize=(20,5))
    rgr = LinearRegression()
    rgr.fit(x,y)
    pred = rgr.predict(x)
    plt.subplot(1, 3, 2)
    res = y - pred
    plt.scatter(pred, res)
    plt.title("Residual plot")
    plt.xlabel("prediction")
    plt.ylabel("residuals")
    plt.subplot(1, 3, 3)
    #Generates a probability plot of sample data against the quantiles of a
    # specified theoretical distribution
    stats.probplot(res, dist="norm", plot=plt)
    plt.title("Normal Q-Q plot")
```


#### Baseline Model:

<p align="justify">In this model, I used only the numercal features which are Price, Beds, Bathrooms, and Sizes and this is what I got.</p> 

![Image test]({{ site.url }}/images/Baseline_ols.png)     

![Image test]({{ site.url }}/images/First_heatmap.png)

This is the cross validation score:
```
Linear Regression  R2  = 0.4988
Ridge Regression  R2 = 0.4989
```
<p align="justify">We can see that the score of R-squared is low and the correlation metrix shows that the size column is highly correlated with my target. In the comming models, I will try to improve R-squared and make sure that the residuals plot is fine.</p>


#### First Model:

<p align="justify">In this model, I added the catogrical feature (Region_Eng) and I noticed that the R-squared improved.</p> 

![Image test]({{ site.url }}/images/Heatmap.png)  

![Image test]({{ site.url }}/images/First_model.png)

![Image test]({{ site.url }}/images/Model_1_residuals.png)


This is the cross validation score:
```
Linear Regression  R2  = 0.626
Ridge Regression  R2 = 0.626
```


#### Second Model:

<p align="justify">In this model, I try to normalize my target by using power transform. The two figures below shows the price distplot before and after using power transform.</p>
```
from sklearn.preprocessing import power_transform
target = df_f['Price'].values.reshape(-1,1)
Target_log = power_transform(target, standardize=True)
```

![Image test]({{ site.url }}/images/before.png)       ![Image test]({{ site.url }}/images/after.png)  

There is an improve in the R-squared now. The below figures shows the R-squared and residuals plot.

![Image test]({{ site.url }}/images/MOdel_2_ols.png) 

![Image test]({{ site.url }}/images/Residuals_second_model.png) 

This is the cross validation score:
```
Linear Regression  R2  = 0.6697
Ridge Regression  R2 = 0.6698
```


#### Third Model:

<p align="justify">In this model, I try to normalize the size feature by using power transform. The two figures below shows the size distplot before and after using power transform.</p>
```
target_sizes = df_f.loc[:, df_f.columns == 'Sizes']
pt = PowerTransformer()
pt.fit(target_sizes)
target_transformed = pt.transform(target_sizes)
```

![Image test]({{ site.url }}/images/beforeSize.png)       ![Image test]({{ site.url }}/images/afterSize.png)  

There is an improve in the R-squared now. The below figures shows the R-squared and residuals plot.

![Image test]({{ site.url }}/images/Model_4_ols.png) 

![Image test]({{ site.url }}/images/Model_4_Residuals.png) 

This is the cross validation score:
```
Linear Regression  R2  = 0.6895
Ridge Regression  R2 = 0.6897
```


#### Testing Final Model (Third Model):

<p align="justify">In this step, I tested my data-test in the chosen model which is the third model and this is what I got.</p> 

![Image test]({{ site.url }}/images/Test_ols.png) 

![Image test]({{ site.url }}/images/Test_residuals.png) 

This is the cross validation score:
```
Linear Regression  R2  = 0.6175
Ridge Regression  R2 = 0.6186
```


## Conclusion and Future Work:

<p align="justify">We can see that when I did a power-transform on the target and the size feature this result a better residuals and R-sqaured score. For future work, I will used a better website or multiple websites that give me more features such as house front, street width, and two other features.</p>



<style>
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>

